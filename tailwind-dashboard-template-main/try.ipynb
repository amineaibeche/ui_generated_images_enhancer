{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import CLIPTokenizer, CLIPTextModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor , CLIPModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_model_name = 'openai/clip-vit-large-patch14'\n",
    "processor = CLIPProcessor.from_pretrained(clip_model_name)\n",
    "model = CLIPModel.from_pretrained(clip_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda10d598446484ead16a76e33417037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82caa7eabd8645db851dfcba8c5718cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as output_image.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "\n",
    "# Device setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the pipeline\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None  # Disable NSFW filter (use with caution)\n",
    ").to(device)\n",
    "\n",
    "# Load initial image (e.g., a sketch or base image)\n",
    "init_image = Image.open(r\"E:\\Amine\\PFE\\IQA\\datset\\AGIQA-3K\\AttnGAN_normal_000.jpg\").convert(\"RGB\")\n",
    "init_image = init_image.resize((512, 512))  # SD v1.5 works best with 512x512\n",
    "\n",
    "# Define prompt and parameters\n",
    "prompt = \"a statue  of  a  man ,naked  realistic  style \"\n",
    "strength = 0.99  # Controls influence of input image (0.0 = no change, 1.0 = full edit)\n",
    "guidance_scale = 9.5  # Controls adherence to the text prompt\n",
    "num_inference_steps = 20\n",
    "\n",
    "# Generate image\n",
    "generator = torch.Generator(device=device).manual_seed(42)  # For reproducibility\n",
    "image = pipe(\n",
    "    prompt=prompt,\n",
    "    image=init_image,\n",
    "    strength=strength,\n",
    "    guidance_scale=guidance_scale,\n",
    "    num_inference_steps=num_inference_steps,\n",
    "    generator=generator\n",
    ").images[0]\n",
    "\n",
    "# Save result\n",
    "image.save(\"output_image.jpg\")\n",
    "print(\"Image saved as output_image.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
